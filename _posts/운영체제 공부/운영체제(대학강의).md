<2.1, 2.2강>

프로세스 / 메모리(instruction의 모음 > 프로그램)
컴퓨터를 키면 프로세스가 메모리의 명령어를 참조
운영체제가 프로그램 실행 / 여러개 동시실행 / 프린터의 인쇄 명령 / 하드디스크의 저장 등등을 할 수 있게 해줌
운영체제 = 컴퓨터 하드웨어(프로세서, 메모리, 디스크, 키보드, 모니터, 네트워크 ...)를 잘 관리하여 성능을 높이고 사용자에게 편의성을 제공
		즉, 컴퓨터 하드웨어를 관리하는 프로그램. 전원 이 꺼질때까지 메인 메모리에 상주함

컴퓨터 구조 : 프로세서 / 메모리(ROM - 극히일부, RAM - 대부분) / 디스크
* ROM : Read Only Memory, 전원이 꺼져도 메모리 유지. 프로세서는 가장 먼저 ROM을 참조함.
	* POST(Power-ON Self-Test) : 메모리 확인, 장치 연결 여부 확인 등등
	* 부트로더(Boot loader) : 하드디스크 내의 OS를 메인 메모리로 가져옴 = Booting

커널(Kernel) : 메모리, 디스크 등을 직접 관리 / 명령 해석기(Shell, command interpreter)

운영체제 = 정부
자원 관리자, 자원 할당자
프로세스 / 메모리 / IO / file / Network / Protect Management ...

Batch processing(일괄처리) : 일정기간이나 한정된 데이터를 모아두었다가 한 시점에 순차적으로 처리하는 방식, resident monitor - 메모리 안에 들어있는 프로그램으로 일괄처리 역할 수행 / 최초의 운영체제
다중 프로그래밍 : CPU scheduling, 메모리 관리 / 보호
Time-sharing system(시공유 시스템) : 강제 절환, interactive system, 가상 메모리, 프로세스간 통신, 동기화

Supercomputer / Server / Workstation / PC / Handheld / Embedded


***


<2.3, 3.1강>

다중 프로세서 시스템(Multiprocessor system) : 병렬 시스템 / 강결합 시스템
분산 시스템(Distributed system) : 다중 컴퓨터 시스템 / 소결합 시스템
3가지 장점 : performance, cost, reliability

실시간 시스템(Real-time system) : 시간 제약(Deadline)이 있음

인터럽트(Interrupt) : 가로채기

하드웨어 인터럽트 / 소프트웨어 인터럽트 / 내부 인터럽트
부팅이 끝나면 os는 메모리에 상주(resident)하며 event를 대기
이벤트가 일어나며 interrpt가 발생하면 CPU는 하던일을 중지하고 Interrupt Service Routine(ISR)을 실행, 종료 후 다시 대기

이중모드(dual mode) : 사용자 / 관리자 모드 = 시스템 모드 = 모니터 모드 = 특권 모드
특권 명령(privileged instructions) : STOP, HALT, RESET ...

레지스터 : CPU가 요청을 처리하는데 필요한 데이터를 일시적으로 저장하는 공간 - cpu의 상태를 나타내는 비트(=flag)들의 모임. 어떤 모드인지에 대한 플래그도 존재.

유저모드 > 이벤트발생 > 시스템모드(ISR) > 유저모드 > 이벤트발생 > 시스템모드 ...
유저모드에서 특권명령을 내렸을 시 내부 인터럽트 발생 > 프로그램 강제종료

하드웨어 보호 : 입출력장치 / 메모리 / CPU
입출력장치 : 입출력 명령을 특권명령으로 IN, OUT - 입출력을 운영체제에게 요청(소프트웨어 인터럽트)하여 시스템모드로 변경 > 운영체제가 입출력 대행 후 다시 유저모드 복귀, 올바른 요청이 아닐경우 거부

메모리 : 다른 사용자 또는 운영체제 메모리에 대한 접근(Segement violation)은 MMU(Memory Management Unit)를 두어 막음
	MMU : CPU 코어 안에 탑재, 가상주소를 실제 메모리 주소로 변환
cpu > memory (address bus), address bus에 base/limit 레지스터를 둠
memory > cpu (data bus)

CPU : CPU 시간 독점 > Timer를 두어 일정 시간 경과시 타이머 인터럽트 > 다른 프로그램으로 강제 전환


***


<3.2, 3.3강>

운영체제 서비스
* 프로세스 관리 : 프로세스 - 메모리에서 실행중인 프로그램.
	* 프로세스 생성 / 소멸
	* 프로세스 활동 일시중지 / 활동재개
	* 프로세스간 통신 / 동기화(synchronization)
	* 교착상태(deadlock) 처리
* 주기억장치 관리
	* 프로세스에 메모리 공간 할당
	* 할당된 메모리 추적 및 감시
	* 프로세스 종료시 메모리 회수
	* 메모리 효과적 사용
	* 가상메모리 - 물리적 실제 메모리보다 큰 용량을 갖도록
* 파일 관리
	* 디스크는 Track/sector로 구성됨. 디스크를 파일이라는 논리적 관점으로 보도록 = Track/sector - file간의 매핑(mapping)
	* 파일 / 디렉토리의 생성 / 삭제
	* 기본동작지원 - open, close, read, write 등 
	* 백업
* 보조기억장치 관리 - Secondary storage
	* 빈 공간 관리
	* 저장공간 할당
	* 디스크 스케쥴링
* 입출력장치 관리
	* 장치 드라이브
	* 입출력 장치의 성능향상 - buffering, caching, spooling
* 네트워킹
* 보호
* ...

시스템 콜 : 운영체제 서비스를 받기위한 호출

프로그램이 실행되면 text / data / stack / pc(program counter) / sp / register 등등이 변함 > 프로세스

프로세스(=task =job) 상태 : new / ready / running / waiting / terminated

PCB(Process Control Block, =TCB) : 프로세스에 관한 모든 정보, 구조체 형식
process state, pc, registers, MMU, CPU time, process id, list of open files ...

JOB Queue - JOB Scheduler(Long-term), new > ready
Ready Queue - CPU scheduler(Short-term), ready > running
Device Queue - Device Scheduler

degree of multiprogramming : 메인 메모리에 프로세스가 몇개 올라와있는가
i/o-bound : i/o 위주 - 워드 등 / cpu-bound : cpu위주 - 일기예보 등 > job scheduler가 이 작업들을 믹스하는 역할도 함
Midium-term scheduler : time-sharing system에서, swapping을 이용(backing store/swap device에서 swap in/out). 현재 사용되고 있지 않은 프로세스를 관리


***


<4.1강, 4.2강>

Context Switching : scheduler / dispatcher - 사용중인 프로세스의 현재 상태 저장, 스위칭할 프로세스의 상태 복원 / context switching overhead 발생

CPU Scheduling : CPU가 메인 메모리 내의 어떤 프로세스를 어떤 순서대로 실행할것인가

Preemptive(선점) - 강제로 프로세스 변경 가능 / Non-preemptive(비선점) - 실행중인 프로세스가 끝나기를 대기

scheduling criteria(척도) : CPU Utilization(이용률) / Throughput(처리율, jobs/time) / Turnaround time(반환시간) - 프로세스 생성부터 소멸까지 걸리는 시간 / Waiting time(대기시간) - Ready Queue에서 기다린 시간 / Response time(응답시간) - 처음 응답이 되기까지 걸리는 시간

CPU Scheduling Algorithms
* First-Come, First-Served(FCFS)
	Average waiting time 기준으로 효율은 좋지 않을 수 있음
	Gantt Chart / Convoy Effect(호위효과) / Nonpreemptive
* Shortest-Job-First(SJF)
	가장 효율적이라는게 증명되었으나, 예측이 필요하기 때문에 현실적이지 못함
	preemptive - Shortest-Remaining-Time-First / nonpreemptive - 일반적인 SJF
* Priority
	우선순위대로. 우선순위는 보통 정수로 표현하며 숫자가 작을수록 순위가 높음
	우선순위 기준 - internal(time limit, memory requirement, I/O to CPU birst) / external
	문제점 - 기아 > againg(나이가 들수록 우선순위 상승)으로 해결
* Round-Robin(RR)
	Time-sharing system에서 많이 사용, 각 프로세스마다 Time quantum(10~100msec, =time slice)의 시간만큼 돌아가며 실행
	Preemptive only
	time quantumd의 크기에 따라 성능이 달라짐
		1. 무한대일경우 : =FCFS
		2. 0일경우 : Proccessor sharing - 모든 프로세스가 각각의 프로세서 위에서 실행되는 것처럼 느껴짐 / 체감 프로세서 속도는 실제 프로세서 성능의 1/n, context switching overhead 발생
* Multilevel Queue
	프로세스는 그룹화가 가능 : system / interactive / interactive editing / batch / student ... 
	각각의 queue에 절대적 우선순위가 존재하여 CPU time이 차등배분됨
	각 queue에는 독립된 scheduling 정책이 적용될 수 있음
* Multilevel Feedback Queue
	프로세스가 cpu로 들어가는 입구는 하나
	하나의 queue가 CPU time을 너무 많이 사용시 다른 queue로 넘어감


***


<4.3강>

프로세스는 프로세스에 의해 만들어짐
부팅 후 첫번째 프로세스가 생성되어 자식 프로세스들을 생성함 : process tree
생성된 프로세스들에는 Process Identifier(PID)가 할당됨
fork() - 부모 프로세스 복사 / exec() - 실행파일을 메모리에 덮어씀 / exit() - 프로세스 종료, 모든 자원(메모리, 파일, 입출력장치 등)이 OS에 반환됨


***


<5.1강, 5.2강, 6,1강>

쓰레드 : 프로그램 내부의 흐름(맥), 한 프로세스에는 최소 1개 이상의 쓰레드가 존재.
다중 쓰레드 : 한 프로그램에 두개 이상의 쓰레드, 쓰레드가 빠른 시간 간격으로 스위칭되어 여러 쓰레드가 동시에 실행되는 것처럼 보임 = concurrent, ex) Web browser / Word ...

구조 : 프로세스의 메모리 공간(code, data)과 자원(file, I/O) 공유, PC / SP / registers / stack 등은 비공유
context switching의 단위는 주로 프로세스가 아닌 쓰레드임

independent process / cooperating process(다른 프로세스에게 영향을 주거나 받는 프로세스)

프로세스 동기화 : 서로 공유하는 데이터에 동시에 접속시 문제가 발생할 수 있음 > 데이터의 일관성이 유지되도록 cooperating 프로세스들을 순서대로 실행

공통변수(common variable)에 대한 동시 업데이트(concurrent update)시 문제가 생길 수 있음 > 한번에 한 쓰레드만 업데이트하도록 = 임계구역 문제

Critical-Section Problem
임계구역 : 여러개의 프로세스/쓰레드로 이루어진 시스템에서 변수 등 공통적으로 사용하는 것이 존재하는 코드 영역
해결방법
	1. Mutual exclusion(상호배타) : 임계구역에는 오직 한 쓰레드만 진입
	2. Progress(진행) : 유한한 시간 내에 쓰레드의 진입 결정이 이루어져야함
	3. Bounded waiting(유한대기) : 대기하는 시간을 한정시켜서 기아 쓰레드가 나오지 않도록 함

프로세스/쓰레드의 동기화 : 임계구역 문제 해결 + 프로세스 실행 순서 제어
동기화 도구 : Semaphore / Monitor

Semaphore(세마포) : 동기화 문제 해결을 위한 소프트웨어 도구, 정수형 변수 + 두개의 동작 (P(test) > acquire(), V(increment) > release())
* acquire시 value(number of permits)값을 1 감소, value가 0보다 작으면 현재 프로세스를 리스트에 넣고 블락
* release시 value값을 1 증가, value가 0 이상이면 list에 있는 프로세스를 깨움
일반적으로 Mutual exclusion(value = 1) / Ordering(value = 0)에 사용


***


<6.2강, 6.3강>

전통적 동기화 예제
1. Producer and Consumer Problem - 생산자-소비자 문제 = 유한버퍼(Bounded Buffer) 문제
2. Readers-Writers Problem - 공유 데이터베이스 접근
3. Dining Philosopher Problem - 식사하는 철학자 문제

Bounded Buffer : 생산된 데이터를 버퍼(크기 유한)에 일단 저장 - 버퍼가 가득 차면 넣을 수 없고, 비어있으면 뺄 수 없음
생산자-소비자 문제 : 생산자가 데이터를 생산하면 소비자가 그 데이터를 소비
	ex) 컴파일러 > 어셈블러 / 파일 서버 > 클라이언트 / 웹 서버 > 웹 클라이언트
	* 공통변수에 대한 동시 업데이트시 임계구역 동시 진입 - 문제발생
		> 상호배타 (mutex, 세마포 등)
	* Busy-wait - 생산자와 소비자는 버퍼의 상태에 따라 무한으로 대기할 수 있음
		> 세마포를 사용해 회피 (empty.acquire, release / full.acquire, release)

Readers-Writers Problem : Reader는 읽기만함, Writer는 읽고 씀 > Reader까지 상호배타에 넣어버릴경우 비효율적임
* The first R/W problem (readers-preference)
* The second R/W problem (writers-preference)
* The Third R/W problem (우선순위 x)

Dining Philosopher Problem : 원형 테이블에 철학자와 포크, 철학자는 생각 > 식사 > 생각 > 식사
기아 철학자 등장 - 교착상태(deadlock)가 발생하기 때문

Deadlock : 프로세스는 실행에 필요한 자원 중 일부를 갖지 못할 때 대기 - 서로 다른 프로세스들이 다른 자원을 가지려고 대기할 때 교착상태 발생
	필요조건 : 상호배타 / 보유 및 대기(Hold and wait) / 비선점(No Preemption) / 환형대기(Circular wait)

자원 : 요청(request) > 사용(use) > 반납(release)
동일 형식의 자원이 여러개 있을 수 있음 - 각각을 instance라고 부름
자원 할당도 - 어떤 자원이 어떤 프로세스에게 할당되었는가(자원-사각형 / 프로세스-원 / 할당-화살표), 할당도 상에 원이 만들어지는 것이 교착상태의 필요조건


***


<7.1강>

교착상태 방지(prevention) : 필요조건 중 하나라도 만족하지 못하게 만들면 됨
	* 상호배타 x - 자원 공유 가능하도록 > 일반적으로는 불가능함
	* 보유 및 대기 x - 일부 자원만 보유하고 있는 경우가 없도록, 자원 활용률이 저하됨 / 기아가 생길 수 있음
	* 선점 o - 일반적으로는 불가능함(ex 프린터)
	* 환형대기 x - 자원에 번호 부여 후 오름차순으로 요청, 자원 활용률이 저하됨

교착상태 회피(avoidance) : deadlock을 자원 요청에 대한 잘못된 승인으로 인식
	자원이 불안정 할당되지 않도록 해야함 > Banker's Algorithm

교착상태 검출 및 복구(detection & recovery) : 교착상태를 허용, 주기적 검사하여 교착상태 발생시 복구
	* 검출 - 검사에 따른 추가 부담이 생김(overhead)
	* 복구 - 현재 상태를 기억해놓을 필요가 있음, 일부 프로세스를 강제 종료 / 자원을 선점하여 다른 프로세스에 할당

교착상태 무시 : 교착상태는 실제로 잘 일어나지 않기 때문...


***


<7.2강, 7.3강>

모니터(Monitors) : 세마포 이후의 프로세스 동기화 도구 - 고수준 개념
* 공유자원 + 공유자원 접근함수 / 두개의 queue (배타동기 + 조건동기)
* 공유자원 접근함수에는 최대 1개의 쓰레드만 진입할 수 있음, 진입 쓰레드가 조건동기로 블록될시(wait) 새 쓰레드 진입가능, 새 쓰레드는 조건동기로 블록된 쓰레드를 깨울 수 있으며(notify) 깨워진 쓰레드는 현재 쓰레드가 나가면 재진입 가능 
* 상호배재 / Ordering에 사용


***


<8.1강>

메모리 역사 : core memory / 진공관 메모리 / 트랜지스터 메모리 / 집적회로 메모리(SRAM, DRAM)
메모리의 크기가 늘어났지만 기계어 / 어셈블리어 > C언어 > 객체지향형 언어, 숫자 / 문자/ 멀티미디어 처리 > 빅데이터 등등으로 프로그램의 크기 또한 증가

메모리 낭비 없애기 / 가상 메모리

메모리 구조 : 주소(Address) + 데이터(Data)
프로그램 개발 : Source file(고수준언어 / 어셈블리어) 컴파일 > Object file(기계어) 링크 - 오브젝트 파일과 라이브러리 연결 > Executable file 로드 - 메인메모리로 로더를 통해 옮김
메모리로 올라간 프로그램은 code / data / stack의 구조로 이루어짐

MMU(Memory Management Unit) : CPU와 메인 메모리 사이, base 레지스터 / limit 레지스터 / 재배치(Relocation) 레지스터(address translation)
	cpu가 인식하는 주소 - 논리주소(logical address) / MMU를 통과하여 메인 메모리에 저장되는 주소 - 물리주소(physical address)


***


<8.2강>

동적 적재(Dynamic Loading) : 프로그램의 모든 루틴(오류처리 등) / 데이터(배열 등)가 전부 사용되는 것은 아님 > 실행시 필요해지면 그때 해당 부분을 메모리에 올림(로드)

동적 연결(Dynamic Linking) : 라이브러리 루틴(printf, 통신 라이브러리 등)이 여러 프로그램에서 공통적으로 사용되고 있을 수 있음 > 링크를 실행시까지 미루고 하나만 메모리에 적재한 후 다른 어플리케이션 실행시 연결시킴
	공유 라이브러리(shared library - linux) / 동적 연결 라이브러리(Dynamic Linking Library - windows)

Swapping : 메모리에 적재되어있으나 현재 사용되지 않고있는 프로세스의 이미지를 Backing store(=swap device, 하드디스크 일부를 사용)로 몰아냄(swap-out) > 프로세스 크기가 크면 backing store 입출력에 따른 부담 발생


***


<8.3강, 9.1강>

다중 프로그래밍 환경 : 부팅 직후 - OS + big single hole / 프로세스 생성&종료 반복 - scattered holes > 메모리 단편화(Memory fragmentation)

메모리 단편화가 발생할경우 hole들이 불연속하게 흩어져있어 프로세스를 적재할 수 없음 = 외부 단편화(external fragmentation) - 전체 메모리의 1/3 낭비

연속 메모리 할당 방식 : First-fit(최초 적합) - 속도 굿, 이용률 굿 / Best-fit(최적 적합) - 이용률 굿 / Worst-fit(최악 적합)
Compaction : hole들을 하나로 모음, 최적 알고리즘이 없어 부담이 큼

페이징(Paging) : 프로세스를 일정 크기(page)로 잘라서 메모리에 넣음 > 외부 단편화 문제 해결, 페이지의 집합 = 프로세스, 프레임의 집합 = 메모리
	MMU가 페이지 테이블(page table)이 되어 CPU가 프로세스를 연속된 메모리 공간에 위치한다고 인식하게 함

주소 변환(Address Translation)
* 논리주소(Logical address) : CPU가 내는 주소는 2진수 m비트 - 하위 n비트는 오프셋 / 변위(d), 상위 m-n비트는 페이지 번호(p)
* 논리주소 > 물리주소 : 페이지 번호는 페이지 테이블의 인덱스 값, p에 해당하는 테이블의 내용이 프레임 번호(f), 변위는 변하지 않음

내부 단편화(Internal Fragmentation) : 프로세스 크기가 페이지 크기의 배수가 아닐경우 마지막 프레임에서 메모리 낭비가 발생 - 최대 페이지 사이즈-1byte만큼

페이지 테이블 : CPU 레지스터 - 주소변환이 빠름, 테이블 엔트리 개수가 적음 / 메모리 - 테이블 엔트리 개수가 충분, 변환속도가 느림 / TLB - 별도의 sRAM으로 (원리는 캐시메모리와 비슷), 변환속도와 테이블 엔트리 개수 모두 중간 
	유효 메모리 접근 시간(Effective memory access time) : T(eff) = h(Tb + Tm) + (1 - h)(Tb + 2Tm), h = hit ratio(보통 95%이상)

보호(Protection) : 해킹 등을 방지, 모든 주소는 페이지 테이블을 경유하므로 페이지 테이블 엔트리마다 r/w/x비트를 두어 해당 페이지에 대한 접근을 제어
공유(Sharing) : 메모리 낭비 방지, 같은 프로그램을 쓰는 복수개의 프로세스의 경우 Code 영역은 공유가 가능함(단 non-self-modifying code = reentrant code여야함, data / stack은 비공유) - 프로세스의 페이지 테이블 코드 영역이 같은 곳을 가리키게함


***


<9.2강>

세그멘테이션(Segmentation) : 프로세스를 논리적 내용(=세그멘트)으로 잘라서 메모리에 배치 - 세그멘트의 크기는 페이지와 달리 일정하지 않음, MMU를 세그멘트 테이블로 사용하여 세그멘트를 메모리에 할당

주소 변환 : 페이징과 비슷, 세그멘트 번호(s) + 변위(d), 세그멘트 테이블 - base / limit(넘어갈 경우 segment violation)

보호 : 페이징과 비슷하게 세그멘트 테이블에 r/w/x비트를 두어 접근 제어, 페이징보다 우월(코드 영역을 확실하게 구분할 수 있기 때문)
공유 : 페이징과 비슷, 페이징보다 우월

외부 단편화 : 세그멘트의 크기는 가변적 > 동적 메모리 할당시 외부 단편화 문제 발생
세그멘트를 페이징 : 세그멘테이션의 보호와 공유 장점, 페이징의 외부 단편화 해결의 장점을 가져옴 > 주소변환의 단계가 하나 더 늘어나 부담이 생김


***


<9.3강>

가상메모리 : 물리 메모리 크기의 한계를 극복(100MB의 메인 메모리에서 200MB 크기의 프로세스를 실행) > 프로세스 이미지 전체 대신 현재 실행에 필요한 부분만 메모리에 올림(오류 처리 루틴등은 바로 필요하지 않음)

Demand Paging : 프로세스는 페이지의 집합 - 전체 프로세스 이미지는 backing store에 저장 / 요구되는 페이지만 메모리에 로드
	valid 비트를 페이지 테이블에 추가하여 구현

페이지 결함(Page Fault, =페이지 부재) : 접근하려는 페이지가 메모리에 없음(invalid) > interrupt를 발생시켜 os안의 루틴 실행 > Backing store에서 해당 페이지를 메모리로 가져옴(handling) > 가져온 프레임 번호를 페이지 테이블에 기록 / valid 비트 설정

pure demand paging : 시작시 아무 페이지도 가져오지 않아 초기 실행할 때부터 페이지 결함 발생 - 속도 저하, 메모리 절약 
preparing : 처음부터 일부 페이지를 가져옴 - 속도 향상, 메모리 낭비

swapping은 프로세스단위 / demand paging은 페이지단위


***


<10.1강, 10.2강>

유효 접근 시간(Effective Access Time) : 페이지마다 읽어들이는 속도가 다름 - 평균 시간을 구한 것이 유효 접근 시간
	* p = page fault가 일어날 확률
	* Tm = DRAM
	* Tp = seek time + rotational delay + transfer time
	* Teff = (1 - p)Tm + pTp
	* p = 1/1000 > 40배 느림 / p = 1/399,900 > 10%느림

Locality of reference(cpu가 참조하는 주소) : 메모리 접근은 시간적 / 공간적 지역성을 가짐 > 실제 페이지 부재 확률은 매우 낮음 
HDD는 접근시간이 너무 길기 때문에 SSD나 저가 DRAM으로 대체해서 사용할 수도 있음

페이지 교체(Page Replacement) : 프로그램을 계속 실행할 시 요구 페이지가 늘어나 언젠가 메모리가 가득 차게됨 > 일부 페이지(victim page)를 backing store로 보내고(page-out) 그 빈 공간에 페이지를 가져옴(page-in)
	* i/o시간 절약을 위해 modify되지 않은 페이지를 victim page로 선택 > modified bit(=dirty bit)를 두어 구현
	* victim 선택 - Random / Page replacement algorithm
		* Page reference string(페이지 참조열) - 페이지 번호가 같은 연속된 주소들을 하나로 묶음
		1. FIFO(First-in First-out)
			초기화 목적의 코드는 처음 실행 이후 필요하지 않을 것이라는 아이디어
			Belady's Anomaly - 프레임 수(메모리 용량)이 증가했음에도 불구하고 PF 횟수가 증가
		2. OPT(Optimal)
			가장 긴 시간동안 사용되지 않을 페이지를 victim으로 선택
			미래는 알 수 없기때문에 비현실적임
		3. LRU(Least-Recently-Used)
			최근에 사용 안되었으면 나중에도 사용되지 않을 것이라고 근사

Global replacement : 메모리 상의 모든 프로세스 페이지에 대해 교체 > 효율이 더 좋을 수 있음
Local replacement : 메모리 상의 자기 프로세스 페이지에 대해 교체


***


<10.3강>

CPU utilization vs Degree of multiprogramming
프로세스 개수가 증가하면 CPU 이용률이 증가하지만, 일정 범위를 넘어서면 감소함 - 빈번한 page in/out > Thrashing으로 인한 i/o시간 증가 때문
	극복 - Global보다는 Local replacement 사용 - 메모리 효율은 감소 / 프로세스당 적절한 수의 메모리(프레임) 할당

프레임 할당(Frame allocation)
* 정적 할당
	* 균등(equal) 할당 : 모든 프로세스에 동일한 프레임 할당
	* 비례(proportional) 할당 : 프로세스 크기별로 비례해서 할당
* 동적 할당
	* Working set model : Locality - 미래예측이 필요 > working set - 과거에 사용된 페이지를 보고 결정 / 얼마만큼의 과거를 볼것인가 = Working set window
	* Page fault frequency : Page fault 발생 비율의 상한선/하한선을 두고 상한선 초과시 프로세스에 더 많은 프레임 할당 / 하한선 이하일경우 프레임 회수


***


<11.1강>

페이지 크기 : 일반적으로는 4kb ~ 4mb, 점차 커지는 경향
	내부 단편화 - 페이지 크기가 작을수록 적게 발생함
	page-in, out시간 - 페이지 크기가 클수록 좋음
	페이지 테이블 크기 - 를 작게하려면 = 비용을 줄이려면 페이지 크기가 클수록 좋음
	Memory resolution - 페이지 크기가 작을수록 좋음
	Page fault 발생 확률 - 페이지 크기가 클수록 낮음

페이지 테이블 : 원래는 별도의 chip(TLB 캐시) > 기술발달에 따라 캐시 메모리가 on-chip 형태로 변함 > TLB도 on-chip 내장으로


***


<11.2강, 11.3강>

컴퓨터 시스템 자원 관리 : CPU - 프로세스관리(CPU스케쥴링, 프로세스 동기화) / 주기억장치 - 메인 메모리 관리(페이징, 가상메모리) / 보조기억장치 - 파일 시스템

보조기억장치(하드디스크) : track / sector, sector size = 512bytes > 여러개 모아서 block단위로 읽고씀 = block device, 디스크 = pool of free blocks

파일 할당
* 연속 할당(Contiguous allocation) : 디스크 상의 연속된 블록 할당
	* 디스크 헤더의 이동 최소화 - 빠른 i/o 성능 > 동영상, 음악 등에 적합, sequential / direct access 모두 가능
	* 파일을 삭제할 경우 홀이 생성되어 외부 단편화 문제 발생 > 디스크 공간 낭비, compaction이 가능하나 시간이 오래걸림, 파일의 크기가 변하는 경우에도 문제 발생
* 연결 할당(Linked allocation) : 연결 리스트 형식으로 - 파일 디렉토리가 가장 처음 블록을 가리킴, 각 블록은 포인터 저장을 위해 최소 4바이트 이상을 소모
	* 새로운 파일 생성시 비어있는 임의의 블록을 첫 블록으로 지정 / 파일이 커질 시 다른 블록을 할당받아 연결 > 외부 단편화 X
	* direct access 불가능, 포인터때문에 4바이트 이상 손실, 포인터가 끊어지면 그 뒤를 접근할 수 없음 > 신뢰성 낮음, 속도 느림
	* FAT(File Allocation Table)로 개선 - 포인터 테이블을 별도 블록에 저장하여 direct access도 가능하도록 함, FAT는 일반적으로 메모리 캐싱, 손실시 복구 위해 복사본을 저장함, window 등에서 사용
* 색인 할당(Indexed allocation) : 파일당 한개의 인덱스 블록(포인터를 모아둔 인덱스 테이블 저장)을 둠, 디렉토리는 인덱스 블록을 가리킴, linux 등에서 사용
	* direct access 가능, 외부 단편화 없음
	* 인덱스 블록으로 인한 저장공간 손실, 파일의 크기에 맞추기 위해 Linked / Multilevel index, Combined 방식 등을 사용


***


<12.1강>

디스크 접근 시간 : Seek time(대부분) + rotational delay + transfer time

디스크 스케쥴링 알고리즘
* FCFS : 간단하고 공평하지만 효율적이지 못함
* SSTF(Shortest-Seek-Time-First) : 가장 짧은 거리의 요청부터 처리, 최적은 아님, 기아가 발생할 수 있음
* SCAN : 헤드가 디스크 전체를 계속해서 가로지르며 스캔, 엘리베이터 알고리즘이라고도 부름
	C-SCAN(Circular SCAN) - 요청이 골구로 분포되어있을 때 유용
	LOOK - 헤드가 해당 방향의 마지막 요청까지만 감
	C-LOOK - LOOK의 Circular 버전