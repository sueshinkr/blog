<1강>

operating system : 컴퓨터 시스템을 운영하는 소프트웨어

컴퓨터란 :  정보를 처리하는 기계

정보란 : 클로드 섀넌이 정의. 불확실성을 측정해서 수치적으로 표현한 것.
* 정보량 I(x) = -log2P(x) (P(x) = 확률). 
* 정보의 최소 단위 = bit(binary digit, P(x)=1/2일 때)
* 정보의 처리 = 정보의 상태 변환(0>1, 1>0)
	* 부울 대수(Boolean ALgebra) - NOT, AND, OR
	* 논리 게이트 : NOT, AND, OR, XOR, NAND, NOR
	* 논리 회로 : IC(집적 회로), LSI(Large Scale), VLSI(Very Large), ULSI(ULtra Large), SoC > 무어의 법칙(집적도가 1.5년마다 두배) / 황의 법칙(메모리가 1년에 두배)
* 정보의 저장과 전송 : 플립-플롭, 데이터 버스, RF(라디오 프리퀀시)

컴퓨터는 정보를 어떻게 처리하나 : 덧셈(가산기), 뺄셈(2의 보수), 곱셈/나눗셈, 실수(부동소수점), 함수(GOTO), ....

그럼 컴퓨터는 만능? : 
* 범용성(universality) : NOT, AND, OR게이트 또는 NAND게이트 만으로 모든 계산 가능. 범용 컴퓨터(general-purpose computer)
* 계산가능성(computability) : Turing-computable / Halting Problem

튜링 머신 / 유티버셜 튜링 머신 / 헤드 > 테이프
응용프로그램 / 운영체제 / CPU > RAM

Stored-program computer : RAM에 프로그램 저장, 저장된 프로그램의 명령어들을 CPU가 fetch > execute. 폰 노이만 아키텍쳐 = ISA(명령어 집합 아키텍쳐)

프로그램 : 컴퓨터의 하드웨어에 특정한 행동을 수행시키는 명령어의 집합

운영체제도 프로그램인가? : 맞음. 컴퓨터에서 항상 실행중인 프로그램. 어플리케이션 프로그램에 시스템 서비스를 제공. 프로세스/리소스/유저 인터페이스 관리.


***


<2, 3강>

하드웨어
os
어플리케이션 프로그램
유저

커널 - os의 핵심

bootstrap program : ROM에 있음. 컴퓨터가 키고나서 가장 먼저 실행되는 프로그램.
하드디스크의 운영체제(특히 커널)를 메모리로 로딩

Interrupts : I/O device와의 통신방법 중 하나. 하드웨어는 언제든 interrupt를 발생시킬 수 있음
보통 system bus를 통해 CPU로 시그널을 전송

storage :
register(cpu 안의 회로) > cache > main memory(ram) > solid-state disk(ssd) > hard disk(hdd) > optical disk > magnetic tapes

CPU : 명령어들을 실행하는 하드웨어
Processor : CPU를 하나 이상 포함한 물리적 칩
Core : CPU의 계산 유닛

Symmetric multiprocessing(SMP) : 가장 일반적인 multiprocessor 시스템. 각각의 cpu가 모든 일을 수행함
Multi-core design : CPU 하나에 코어(register와 cache를 포함한)가 여러개

Multiprogramming : 한번에 하나 이상의 프로그램을 실행. 메모리에 여러개의 프로세스들을 동시에 유지시킴 > CPU의 효율 증가
Multitasking(=multiprocessing) : CPU가 job을 자주 바꿔서 유저가 각각의 job과 상호작용할 수 있음. concurrency / paralelism

CPU scheduling : 여러 프로세스가 동시에 준비되어있을 때 시스템은 어떤 프로세스를 다음에 실행시킬건지 선택해야함

user mode / kernel mode : system call은 kernel mode에서만 처리하여 비정상적인 프로그램 실행을 막음

Virtualization : 하드웨어 위에 vmm 레이어를 올리고 그 위에서 각각의 커널을 관리

Traditional / Mobile / Client-server / Peer-to-Peer / Cloud / Real-Time Embedded Systems

OS는 프로그램의 실행을 위한 환경을 제공 :
User Interface / Program execution / IO operation / File-sysstem manipulation / Communications / Error detection / Resource allocation / Logging / Protection and security
가장 중요한건 process와 thread의 multiprocessing > synchronization / deadlock

OS에 접속하기 위해 유저가 사용할 수 있는 방법 : 
CLI : command line interface
GUI : graphical user interface
Touch-Screen Interface

응용프로그램은 OS가 제공하는 서비스들을 System call을 통해 호출
API : Application Programming Interface, OS의 API가 system call

Process : 실행중인 프로그램. 운영체제의 작업 단위.
프로세스가 실행되기 위해서는 CPU time / memory / files / IO devices 등의 자원이 필요

Text - executable code / Data - global variables
Heap - 동적할당 / Stack - 지역변수, 함수 패러미터, 반환 주소값 등의 임시 데이터

Process state : 
* New : 프로세스가 막 생성된 상태
* Running : 명령어들이 실행중
* Waiting : 특정한 이벤트(IO 시그널 입력 등)가 일어나기를 대기. 
* Ready : 프로세서에 할당되기를 대기중
* Terminated : 실행 종료
ready queue와 wait queue가 존재

PCB(Process Control Block) / TCB(Task Control Block) : 각 프로세스의 정보를 구조체에 저장 - Process state, Program counter, CPU registers, CPU-scheduling information, Memory-management information, Accounting information, I/O status information
프로세스 = 단일 쓰레스 실행을 수행하는 프로그램
쓰레드 = lightweight process
요즘엔 대부분 multiprocessing보다는 multithreading 위주임.

multiprogramming(multiprocessing)의 목적 : 프로세스가 항상 실행되도록 하여 CPU 효율을 극대화하기 위해
time sharing의 목적 :  프로세스간에 CPU core를 자주 전환하여 유저가 각 프로그램이 실행되는 동안 상호작용을 할 수 있도록 하기 위해

프로세스의 context는 PCB를 의미. 간섭이 발생하면 시스템은 실행중인 프로세스의 현재 context를 저장하고, 후에 복원할 수 있음.
Context Switch : CPU core를 다른 프로세스로 전환 = 현재 프로세스의 상태 저장, 다른 프로세스의 상태 복원

자식 프로세스가 부모 프로세스를 복제하는 경우 / 새로운 프로그램을 로드하는 경우
프로세스가 종료되면 os는 모든 자원을 할당 해제 및 환원함

고아프로세스 : 부모 프로세스가 wait 없이 먼저 종료된 경우
좀비프로세스 : 프로세스가 종료되었으나 부모가 wait하지 않아 종료 상태가 회수되지 않았을 경우


***


<4, 5강>

UNIX-like OS에서는 새 프로세스를 fork() 시스템 콜으로 생성
자식 프로세스는 부모 프로세스의 주소공간을 복사, 두 프로세스는 fork 이후의 명령어들을 계속 실행
pid가 0이면 자식, nonzero면 부모
부모에 wait()을 걸면 부모 프로세스는 wait queue로 이동하여 자식 프로세스가 끝나기를 대기함

부모와 자식 프로세스중 어떤게 어떤 순서로 실행되는지는 보장되지 않음 - time-scheduling에 따른 context switch 때문

프로세스들이 independent : 프로세스끼리 데이터를 주고받지 않아 문제의 여지가 없음
프로세스들이 cooperating : 프로세스끼리 데이터를 주고받으며 영향을 주고받음 = IPC(Inter-Process Communication) - shared memory / message passing

Prodoucer-Consumer Problem : 컴파일러가 어셈블리 코드를 생산, 어샘블러가 소비 / 웹서버가 HTML 파일 생산, 브라우저가 소비 등등

shared-memory : 생산자와 소비자가 concurrently하게 실행되도록 하기 위해
shared-memory를 buffer로 사용. 생산자는 buffer를 채우고, 소비자는 비움
단점 - shared memory에 엑세스하거나 조작하는 코드를 응용 프로그램 프로그래머가 따로 명확하게 작성해야함

Message-Passing : OS가 프로세스들에 커뮤니케이트 수단을 제공 - 성능은 떨어지나 동기화 문제는 발생하지 않음, send / receive
communication link - direct / indirect, synchronous / asynchronous, automatic / explicit buffering

direct : 누구한테 주는지 명시, 정확히 두개의 프로세스들 사이의 링크가 자동적으로 생성되고 이 링크는 하나밖에 존재할 수 없음
indirect : 포트(port)를 이용, 프로세스들(두개 이상도 가능)이 포트를 공유할 때 링크가 생성됨, 여러개의 링크가 존재할 수 있음

Blocking(>synchronous) : 버퍼에 차있는 메세지가 소비될때까지 전송이 블락됨
Non-blocking(>asynchronous) : 메세지를 보내놓기만 하면 os가 처리


***


<6강>

IPC SYstem (하나의 컴퓨터 내부의 두 프로세스간 통신)
* Shared Memory : POSIX Shared Memory
	shared memory 파일을 Memory에 매핑 
	1. fd = shm_open(name, O_CREAT | O_RDWR, 0666);
	2. ftruncate(fd, 4096);
	3. mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
* Message Passing : Pipes - 두개의 프로세스가 커뮤니케이션하는 도구
	unidirectional (O) / bidirectional, half-duplex (O) / full-duplex, relationship, network(x, > socket)
	Ordinary pipes : 부모가 파이프를 생성, 자식과의 커뮤니케이션을 위해 사용
	Named pipes : parent-child 관계가 필요없음

소켓(Sockets) : 통신을 위한 양 종단(endpoints), IP주소와 port를 하나로 묶은 것
TCP(Server Socket, connection-oriented) / UDP(Datatgram Socket, connectionless) / MUlticast Socket

RPCs(Remote Procedure Calls) : 네트워크화된 시스템들의 프로세스들 사이의 원격 함수를 호출, 가장 일반적인 형태의 원격 서비스
클라이언트가 stub을 통해 서버의 함수를 확인 > marshaling - 원격 서비스를 이용하는 api끼리 주고받는 데이터를 정렬


***


<7깅>

하나의 프로세스가 여러개의 쓰레드를 가질 수도 있음

쓰레드(thread) = lightweight process. cpu를 점유하는 최소단위
pid 안에 여러개의 tid(thread ID)가 있을 수 있음. 쓰레드별로 별개의 pc, register set, stack을 가짐

멀티쓰레딩 : web server같은 client-server system에서 요청이 들어올 때마다 쓰레드를 생성하여 처리
1. Responsiveness - block되지 않고 계속 execution할 수 있음
2. Resource Sharing - shared-memory나 message-passing보다 쉬움 (data영역을 공유하기 때문)
3. 프로세스를 만드는 것 보다 쌈
4. Scalability(확장성) - 멀티프로세서 구조의 장점(병렬처리)을 가져올 수 있음

멀티코어 시스템에서의 멀티쓰레딩 : concurrency의 향상
네개의 쓰레드가 있는 경우 : single core - 쓰레드들이 interleaved됨 / multiple cores - 쓰레드들을 병렬적으로 실행가능

고려할점
1. Identifying tasks : 어떤 작업을 병렬적으로 할 수 있는지
2. Balance : 동일한 일을 할당
3. Data splitting : 데이터가 각 코어에서 실행가능하도록 나뉘어져야함
4. Data dependency : 동기화 문제
5. Testing and debugging : 싱글쓰레드보다 훨씬 어려움

data parallelism / task parallelism < 분산시스템의 등장으로 크게 중요하지는 않음

암달의 법칙(Amdahl's Law) : speedup <= 1 / (S + (1-S)/N) (S - 시스템에서 직렬적으로 수행되어야 하는 부분, N - 프로세싱 코어 개수)


***


<8강>

유저 쓰레드 - 유저 모드 위에서 / 커널 쓰레드 - OS가 직접
Many-to-one(유저 쓰레드 여러개가 하나의 커널 쓰레드에) / One-to-One / Many-to-Many

쓰레드 라이브러리 : 쓰레드를 만들고 관리하는 API, POSIX Pthreads / Windows thread / Java thread

Implicit Threading : concurrent 하고 parallel한 어플리케이션을 디자인하는건 어려움 > 어려운 일을 컴파일러나 run-time 라이브러리로 넘김
	Thread Pools : 여러개의 쓰레드들을 pool에 저장해 사용, 사용자가 직접 쓰레드를 만드는 것이 아니라 미리 만들어져있는 pool에서 가져옴
	Fork / Join : explicit뿐만 아니라 implicit하게도 사용 가능
	OpenMP : 컴파일러 지시어 모음 / API, C/C++에서 사용
		코드블럭에서 parallel region을 지정 후 컴파일러에게 지시 > 해당 부분을 OpenMP 라이브러리가 해당 부분을 parallel하게 실행
	GCD(Grand Central Dispatch) : Mac OS / iOS에서 사용


***


<9강, 10강>

CPU scheduling : 멀티프로그래밍의 기반 - CPU의 효율을 극대화하기 위해 프로세스들이 항상 실행되도록 한 것이 멀티프로그래밍의 목적
CPU bound보다 IO bound가 많음
ready 상태의 프로세스들 중 어떤 프로세스를 CPU에 할당시켜줄것인가?

Preemptive / Non-preemptive

FIFO Queue(First-in, First-out) / Priority Queue

1. running > waiting : non-preemptive
2. running > ready : preemptive / non-
3. waiting > ready : preemptive / non-
4. terminate : non-preemptive

dispatcher : context switch를 해주는 모듈
	context를 다른 프로세스로 전환(현재 프로세스 상태 저장, 스위칭할 프로세스의 상태 복원) / 유저모드로 전환 / 유저 프로그램의 복원을 위해 적당한 위치로 점프
	dispatcher latency는 가급적 짧아야함

CPU utilization - 이용률 / Throughput - 처리율/ Turnaround time - 반환시간 / Waiting time - 대기시간 (가장중요) / Response time - 응답시간

1. FCFS(First-come, First-Served)
	프로세스들의 CPU-burst에 따라 AWT가 많이 달라짐, non-preemptive
2. SJF(Shortest Job First) 
	CPU-burst가 작은것부터. 이론적으로 최적임이 증명되었으나 구현이 힘듬 - 다음 프로세스의 CPU burst를 알 수 없음 > 예측 - 과거 측정된 값으로 지수적 평균 사용
	preemptive / non-preemptive 둘다 가능, preemptive의 경우 SRTF(Shortest Remaining Time First)
3. RR(Round-Robin)
	= preemptive FCFS. time quantum(=time slice, 10~100밀리초)가 지나면 다음 프로세스로 변경
	CPU burst가 time quantum보다 짧은경우 - 프로세스가 CPU를 자발적으로 빠져나와 스케쥴러는 ready queue의 다음 프로세스를 진행함
	CPU burst가 time quantum보다 긴 경우 - interrupt를 걸어 context switch 발생, 프로세스는 ready queue의 끝으로 들어감
	평균 대기시간이 종종 더 길 수 있음. time quantum의 크기에 따라 스케쥴러의 성능이 달라짐
4. Priority-based
	각 프로세스의 우선순위를 둠. 동일한 우선순위 = FCFGS, 특수 케이스(CPU burst에 따른 우선순위) = SJF
	preemptive로 만들경우 starvation(기아, =indefinite blocking)이 발생할 수 있음 > aging(점진적으로 프로세스의 우선순위를 증가)으로 해결
5. MLQ(Multi-Level Queue)
	각 프로세스 그룹마다 우선순위를 두어 ready queue를 따로 둠
6. MLFQ(Multi-Level Feedback Queue)
	실제적으로 많이 사용됨

현대 OS에서는 프로세스가 아닌 커널 쓰레드를 스케쥴링함 - 유저 쓰레드는 쓰레드 라이브러리가 관리

Real-Time(주어진 시간 내에 정해진 task 완료) OS
	soft real-time : 중요한 real-time 프로세스가 우선하는 것은 보장되나 정해진 시간 내에 완료되는 것은 보장하지 않음
	hard real-time : task가 반드시 deadline안에 서비스되도록 함, 우선순위 역전 등 발생


***


<11강>

data consistency를 위해 cooperating 프로세스들의 실행 순서를 보장해야함
concurrence하게 실행된 프로세스들 사이에서 콘텍스트 스위칭이 일어나면 레지스터 값을 저장하고 복구하는 과정에서 어긋날 수 있음 - 명령어들이 임의적인 순서로 끼어들기 때문

Race Condition(경쟁상태) : 여러개의 프로세스 또는 쓰레드들이 같거나 공유된 데이터에 concurrently하게 접근하거나 조작할 경우의 실행 결과는 어떤 순서가 되는지에 따라 달라짐
> 이 상태가 되는 것을 막기 위해 프로세스들이 동기화되도록 해야함
ex) pid를 부여할 때

Critical Section(임계영역) 문제 : n개의 프로세스들이 있을 때, 각 프로세스들은 임계 영역이라고 부르는 코드 영역을 가지고있음 - 이 영역이 다른 프로세스들과 공유되어있을 때의 문제
> 한 프로세스가 임계영역을 실행중이면 다른 프로세스들이 접근할 수 없도록 만들어서 해결
임계 영억을 동시에 실행하는 경우가 없으면 프로세스들의 동기화가 가능해지고 따라서 cooperative한 데이터 공유가 가능해짐

코드 영역
entry-section - 임계영역에 진입하겠다는 허가를 요청 > critical-section > exit-section > remainder-section

세가지 요구사항
1. Mutual Exclusion(상호배제) : 프로세스가 임계영역을 실행중이라면 다른 프로세스는 실행할 수 없어야함
2. Progress(avoid deadlock) : 임계영역을 실행중인 프로세스가 없을 때, 진입하고자 하는 프로세스의 선택이 무한히 연기됨
3. Bounded Waiting(avoid starvation) : 임계영역에 들어가고자 대기하는 시간을 한정시켜서 기아 프로세스가 없도록

싱글코어 환경에서는 shared variable을 수정하는 동안에는 interrupt가 발생하지 않도록 하여 해결 > 멀티코어 환경에는 적합하지 않음

non-preemptive 커널 - 커널 모드가 끝날때까지 CPU 점유 > Race condition이 발생하지 않음
preemptive 커널 - 디자인이 어렵지만 훨씬 응답성이 좋음


***


<12강>

Dekker 알고리즘 : 두 프로세스
Eisenberg and McGuires 알고리즘 : waiting time이 n-1을 lower bound로 가지는 n개의 프로세스
Peterson 알고리즘 : 임계구역 문제를 해결한 고전적 방법으로 증명가능하며 개념적으로는 완벽함, flag와 turn 변수를 두어 두 프로세스가 번갈아가며 실행되도록 함
entry-section에서 권한을 주는 과정에서 context switching이 일어날 수 있음 - 알고리즘이 정상적으로 작동한다는 보장은 없음

하드웨어 instruction을 사용하여 CSP문제 해결을 지원 : memory barriers or fences / hardware instructions / atomic variables

atomicity(원자성), atomic operation = 더이상 쪼갤 수 없는 operation의 단위
test_and_set / compare_and_swap을 hardware instruction으로 만들어 atomic operation 생성

atomic variable : 경쟁 상태에 있는 한 변수에 대한 atomic operation을 만들어 사용


***


<13강>

Higher-level software tool for CSP
* Mutex Locks - 동기화의 가장 간단한 툴, 프로세스/쓰레드 2개 제어
* Semaphore : 더 탄탄하고 편리하고 효과적인 툴, n개 제어
* Monitor : mutex와 semaphore의 단점 극복
* Liveness : deadlock 문제도 해결

Mutex : mutual exclusion 구현, acquire / release - atomically하게 실행되어야함 > compare_and_swap operation을 통해 충족
	Busy waiting : acquire 호출 대기중 무한히 loop - CPU cycle을 낭비
	Spinlock : busy waiting 상태를 만든 mutex lock - context switch하는 시간을 절약하여 장점이 될 수 있음, 멀티코어 시스템에서는 장점이 될 수 있음

Semaphore : P(wait) / V(signal), 변수를 ++(signal) / --(wait) 해가며 조절 - 변수가 0이되면 모든 자원이 사용중 > 다음 프로세스는 블락됨
	Binary Semaphore : 변수 0 ~ 1 = mutex lock
	Counting Semaphore : 변수제한 x - 여러개의 instance를 가진 자원에 사용가능
	Busy waiting 문제 발생 - P와 V를 수정하여 극복
		Wait : 변수가 0이하이면 루프를 도는 대신 waiting queue로 보냄
		Signal : waiting queue에 가있던 프로세스를 깨워 ready queue로 보냄


***


<14강>

세마포는 타이밍에러가 자주일어나고 잡기도 힘듬
ex) 모든 프로세스들이 binary 세마포 뮤텍스(1로 초기화)를 사용할경우 - 각 프로세스들이 wait>signal의 순서를 지키지 않았을 경우
따라서 high-level language construct를 사용

Monitor = high-level synchronization construct
모니터 타입 : ADT(Abstract Data Type) - 상보해재를 제공하는 일종의 데이터 타입(java의 클래스같은), 변수를 선언하고 변수에 정의된 instance를 호출
	* shared data / operations / initialization code를 하나로 묶음(class / struct 등) > entry queue
	* Conditional Variables : 모니터 자체로는 동기화문제를 풀기에 충분치 않아 condition 변수를 더해줌 > 컨디션 변수를 wait / signal
	* java에서는 쓰레드 동기화를 위한 monitor-lock(intrinsic-lock)을 제공함

Liveness : 상호배재 뿐만 아니라 progress와 bounded-wating까지 해결

Deadlock : 두개 이상의 프로세스들이 무한정으로 대기하는 상황
Priority Inversion : 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스가 자원을 사용하는동안 기다리는 상황 > priority-inheritance로 회피


***


<15강, 16강>

Concurrency-Control Problem
1. Bounded-Buffer : 생산자 소비자문제
	n개의 버퍼 공유, 채우고 비울 때 문제 발생
2. Readers-Writers Problem
	Reader들은 동시에 실행되도 아무런 문제가 없음
	* first problem - reader가 writer를 기다리지 않을 경우
	* second problem - wrtier가 reader보다 높은 우선순위
3. Dining-Philosophers Problem
	세마포를 이용한 상호배제를 적용하면 deadlock과 starvation이 발생함
	* 데드락 해결 - 철학자 수 제한 / 양 젓가락을 모두 쓸 수 있는 경우에만 집도록 허용 / 홀수는 왼쪽, 짝수는 오른쪽부터 > 전부 기아까지 해결할 수는 없음
	* 모니터 도입(양 젓가락 동시허용) - 배고픈상태를 추가, 먹는상태가 되기 위해서는 양쪽의 철학자들이 먹는상태가 아니여야함, 조건 변수를 두어 배고픈 상태일때 대기하도록 만듬

thread-safe concurrent applications
1. Transactional Memory : atomic operation 사용
2. OpenMP
3. Functional Programming Language : 명령형(imperative) 대신 함수형 프로그래밍 사용


***


<17강, 18강>

Deadlock : 특정 프로세스들 모두가 다른 프로세스가 야기하는 이벤트를 대기하고있는 상태 = 쓰레드(혹은 프로세스)의 상태가 절대로 변하지 않는 상황

Request - Use(여러개의 자원 사용 가능) - Release

Deadlock이 발생하는 네가지 필요조건
1. Mutual Exclusion
2. Hold and Wait
3. No preemption
4. Circular Wait

Resource-allocation graph에서 cycle을 쉽게 확인

Deadlock 문제해결
1. Ignore
2. Prevention(거의 불가능) / Avoidance(Banker's algorithm)
3. allow - detect > recover

Deadlock Prevention : 4가지 조건중 하나만 만족하지 않게 해도 가능
* 상호배제 - 모든 자원이 sharable하도록 > 불가능
* 점유대기 - 어떤 자원도 hold되지 않도록 > 가능하긴 하나 실용적이지 못함
* 비선점 - 선점이 가능하도록 > 대부분 어플리케이션에 적용 불가능
* 환형대기 - 자원에 순서를 붙여 오름차순대로 요청 > 가장 현실적이나 기아가 발생할 수는 있음, deadlock prevention을 완벽히 보장하지는 않음

Deadlock Avoidance : 요청이 왔을때 데드락 가능성을 회피하기위해 쓰레드가 대기하도록, 자원이 어떻게 요청되는지에 대한 정보가 필요함 - 필요로하는 최대 자원 / 사용가능한 자원 / 할당된 자원 수 > 데드락 상태에 절대 진입하지 못하도록 알고리즘을 설계
	Safe state : 시스템이 자원들을 각각의 쓰레드에게 할당 가능한 특정 순서가 존재
	인스턴스가 하나일경우 RAG에 claim edge를 도입해서 확인 가능
	인스턴스가 여러개인경우 Banker's algorithm 도입 > RAG보다 덜 효율적이고 더 복잡함

Banker's algorithm
n - 쓰레드 수 / m - 자원 수
Available(사용가능한 자원 수) / Max(각 쓰레드의 최대 요구치) / Allocation(각 쓰레드에 현재 할당된 자원) / Need(각 쓰레드가 현재 필요로하는 자원 수)
	Safety algorithm 
		1. finish[i] = false, work = available로 chrlghk
		2. finish[i]가 false이고 need[i] <= work이면
			work = work + allocation[i], finish = ture
		3. finish가 전부 true가 될때까지 반복
	Resource-Request algorithm
		1. request[i] <= need[i]가 아니면 경쟁상태 유발
		2. request[i] <= available이 아니면 T[i]는 기다려야함
		3. 위 두가지 조건에 걸리지 않는다면
			available = available - request[i], allocation[i] = allocation + request[i], need[i] = need[i] - request[i]

Deadlock Detection : 데드락을 허용하고, 데드락이 발생했을 경우를 감시 / 복구
	인스턴스가 하나일경우 wait-for graph를 사용
	인스턴스가 여러개일 경우 banker's algoritm과 비슷한 알고리즘을 설계
	데드락이 얼마나 자주 일어나는가 / 데드락에 영향을 받는 쓰레드가 몇개인가
	데드락이 일어난경우 - 대부분은 관리자 호출, 혹은 자동적으로 복구
		1. Proceess / Thread Termination - 모두 / 데드락이 끝날때까지 한번에 하나씩
		2. Resource Preemption - selecting a victim / rollback / starvation


***


<19강>

프로세스 = 실행중인 프로그램 = 메인 메모리에 올라와있는 명령어 집합
base / limit 레지스터로 각 프로세스의 엑세스 공간을 관리 > 하드웨어로 구성

Address Binding : 프로그램에서 주소를 다루는 방법은 전부 다름 - source의 주소들은 일반적으로 symbolic하고 컴파일러는 이를 relocatable address로 바인딩함 > 이후 linker가 로드하면서 해당 주소를 absolute address로 바인딩함

Logical address : cpu가 사용하고있는 주소 / Physical address : 메모리가 보는 주소

MMU(Memory Management Unit) : logical 주소를 physical 주소로 변환해주는 하드웨어 장치
	* relocation register - MMU의 기본 레지스터

Dynamic Loading : 전체 프로그램이나 데이터가 메모리에 옮겨질 필요는 없음 > 필요할때만 각 루틴을 로딩
DLL(Dynamic Linked Library) : 유저 프로그램이 실행중일 때 시스템 라이브러리와 링크됨
	Static linking - 시스템 라이브러리가 로더에 의해 바이너리 프로그램에 합쳐짐
	Dynamic linking - 링킹을 실행시까지 연기
	Shared library - window에서는 .dll / 리눅스에서는 .so

Contiguous memory allocation : 각 프로세스가 메모리의 single section에 들어있음 > relocation / limit register로 메모리 보호

Variable-Partition scheme : 프로세스들을 메모리의 다양한 크기의 파티션에 할당 > hole이 생김
	hole 관리를 어떻게 할것인가 - First-fit / Best-fit / Worst-fit

Fragmentaiton
* external fragmentation : 많은 수의 작은 hole들이 메모리 낭비
* internal fragmentation : 페이징시 마지막 프레임을 페이지가 채우지 못해 메모리 낭비


***


<20강>

Paging : 물리 메모리를 fixed-sized block(frame)으로 나누고 논리 메모리를 같은 크기의 블럭(page)로 나눔, 논리 주소와 물리 주소가 완전히 분리 > 외부 단편화 회피
	page number(p) / page offset(d)
	p를 page table의 인덱스로 사용하여 frame number(f)를 구함
	> f에 해당하는 프레임에서 d만큼 오프셋된 위치가 실제 물리적 주소가 됨
	페이지의 크기는 하드웨어에 의해 정의됨 - 2의 거듭제곱수.
	logical address space의 크기가 2^m, 페이지 크기가 2^n일 경우 상위 m-n개 비트는 페이지 번호, 하위 n개 비트는 페이지 오프셋을 가리킴

PTBR(page-table base register) : 페이지 테이블의 시작주소를 가리킴, 페이지 테이블은 메인 메모리에 있음 - context switching은 빠르지만 memory access는 느림(두번의 메모리 엑세스)
TLB(Translation Look-aside Buffer) : 하드웨어 캐시 메모리, TLB hit / miss - hit ratio에 따라 효율이 달라짐

페이징은 각 프레임에 protection bit를 사용 - valid-invalid bit(valid하면 legal, invalid면 illegal)

Shared pages : code가 reentrant code(non-self-modifying code)일 경우 공유될 수 있음 

페이지 테이블 자체가 커짐 : Hierachical Paging - logical address space를 multipe tables로 나눔 / Hashed Page Table - 해쉬 테이블 사용 / Inverted page Talbe : 프로세스에 대한 정보가 포함된 가상 주소로 구성된 각 실제 페이지에 대한 항목인 inverted page table 사용(pid 사용)

Swapping : 모든 프로세스의 총 물리적 주소 공간이 시스템의 실제 물리적 메모리를 초과할 수 있도록 프로세스나 프로세스의 일부분을 backing store로 swap out / 메인 메모리로 swap in시킴 > degree of multiprogramming을 증가
Standard Swapping - 프로세스 전체를 메인 메모리와 backing store 사이에서 움직임, 코스트가 매우 비쌈
Swapping with Paging - 작은 수의 페이지들만 swapping됨, page out / page in, 가상 메모리에서 잘 작동함


***


<21강>

가상 메모리 : 프로그램이 물리 메모리모다 클 수 있음 > 메인 메모리를 매우 큰 array of storage로 ㅜ상화하여 논리적 메모리를 분리
	page sharing을 통해 파일과 메모리가 두개 이상의 프로세스들에게 공유될 수 있음

demand paging : 물리 메모리에 전체 프로그램을 로드하지 않음 - 필요한 페이지만 로드, 페이지가 메모리에 있는지 secondary storage에 있는지 구분은 valid bit를 사용
	pude demand paging / preparing

Page Fault : internal table 체크 - valid일 경우 정상처리, page fault일 경우 비어있는 프레임을 찾아 page in시킴 > internal table 수정

Locality of Reference : 프로그램이 가지는 경향 > demand paging이 합리적인 성능을 낼 수 있음

Instruction Restart : page fault가 발생했을 때 interrupted된 프로세스의 상태가 저장됨 > 프로세스가 정확이 같은 공간과 상태에서 재실행됨

effective access time = (1 - p) * ma + p * page fault time
	p = page fault가 발생할 확률
	ma = memory-access time
	page fault time = service the page-fault interrupt + read in the page(대부분) + restart the procees

Copy-on-Write : 프로세스가 write 할때만 shared page를 copy


***


<22강>

free frame이 없을 경우 문제 발생 > 현재 사용되지 않는 frame을 찾아 free시켜주고 사용해야하는 페이지로 교체 = Page replacement

page fault가 발생한경우
	1. secondary storage에서 필요한 페이지를 찾음
	2. free frame이 있으면 사용
	3. 없으면 page-replacement 알고리즘을 통해 victim frame을 찾아 교체

Second storage I/O는 시간이 많이 걸리기 때문에 demand paging의 효율을 조금만 올려도 시스템 성능을 큰폭으로 향상시킬 수 있음

Page-replacement algoritm : reference string 이용
* FIFO : 오래된 순서대로 out(과거기준) - Belady's Anomaly(프레임 수가 늘어났음에도 불구하고 page fault가 늘어나는 현상)이 발생
* OPT : 가장 긴 시간동안 사용되지 않을 페이지를 out(미래기준) - 미래예지가 필요... > 실현 불가능
* LRU(Least Recently Used) - 가까운 미래의 추측 = 가장 오랜 기간동안 사용하지 않은 페이지를 out, 프레임이 언제 마지막으로 사용되었나에 대한 데이터가 필요 > 하드웨어 지원(counter / stack)이 요구되지만 많은 시스템들이 reference bit만 지원함
* Second-Chance : FIFO 알고리즘 사용, reference bit가 0이면 교체 / 1이면 다음 프레임 확인

Frame Allocation : n개 프로세스에 m개의 프레임을 할당해야하는경우
* Equal / Proportional
* Global / Local

Thrashing : 일반적으로 degree of multiprogramming과 CPU utilization은 비례하지만 어느순간 확 낮아짐 = Thrashing 발생 > 프로세스가 충분한 페이지를 가지지 못했을 경우 page-fault rate가 높아지는 현상 (빈번한 page in/out 때문)

Working-Set Model : locality에 기반, 최근 페이지 references들의 집합을 working-set으로 둠, 페이지가 사용중이면 working-set에 포함되어있음 / 사용되지 않으면 working-set 외부 > victim으로 선정


***


<23강>

Mass-Storage : =secondry storage, 보통 HDD(Hard Disk Drive)나 NVM(Non-Volatile Memory) / 마그네틱 테이프나 광학디스크, 클라우드를 이용하는 경우도 있음

HDD Scheduling : seek time을 최소화 / 데이터 전송의 bandwidth(대역폭)를 최대화
	seek time - 장치의 arm이 헤드를 목표 섹터가 들어있는 실린더까지 움직이는데 걸리는 시간
	disk bandwidth - 총 전송되는 바이트를 총 걸리는 시간으로 나눈 값
	* FIFO
	* SCAN : 디스크 암이 한쪽 끝에서 끝으로 움직이면서 각 실린더에 닿을때마다 요청 수행
	* C-SCAN(Circular-SCAN) : SCAN의 일종으로 더 균등한 wait time을 가짐, 한쪽 방향으로 갈때만 읽어들임 - 실린더들을 원형 리스트처럼 다룸

Boot Block : bootstrap loader는 NVM flash memmory에 저장되어있음

RAID(Redundant Arrays of Independent Disks) : 데이터를 읽고쓰는 효율 향상 - 드라이브가 병렬적으로 다루어질 경우, data storage의 신뢰성 향상 > drive의 failure가 데이터의 손실로 이어지지 않도록
Redundancy : N개의 디스크는 싱글 디스크보다 오류가 발생활 확률이 높음 - 신뢰성 문제를 해결하는 방법 > redundancy, 가장 쉬운 방법은 mirroring(모든 드라이브를 복제)

Parallelism : 여러개의 드라이브가 있을 경우 데이터를 striping하여 성능 향상, bit-level striping / block-level striping

parity bit : 바이트의 비트 수에 따라 홀 / 짝을 나누어 에러 검출

RAID
* 0 : non-redundant stiriping
* 1 : mirrored disks
* 4 : block-interleaved parity
* 5 : block-interleaved distributed parity
* 6 : P(parity bit) + Q(queue) redundancy
* Multidimensional RAID 6

컴퓨터의 두가지 주요 역할 : I/O와 계산 > 많은 경우에서 메인은 I/O(웹 브라우징, 파일 수정, 유튜브, 게임 등등), I/O에서의 운영체에의 역할은 I/O operation과 I/O device의 관리와 제어

Memory-Mapped I/O : 디바이스에 내리는 명령을 어떻게 전달할것인가 - 제어 레지스터들을 프로세스의 주소 공간에 매핑 > CPU가 I/O 요청을 실행하면 물리 메모리에 매핑되어있는 레지스터들을 읽고 씀
	data-in / data-out / status / control register

I/O type
* polling(or busy-waiting) : busy bit이 clear될때까지 status 레지스터를 계속 읽음
* interrupt : CPU가 interrupt-request line을 사용 > CPU가 interrupt를 발견하면 ISR(interrupt service routine)에 제어권을 넘김, ISR의 주소는 interrupt vector table에 저장되어있음
* DMA(Direct Memory Access) : programmed I/O(한번에 한 바이트)를 회피하기 위해 사용 > 대용량 데이터 전송을 다루는데 유용

Blocking I/O : 쓰레드가 유예됨 > running 큐에서 waiting 큐로 이동
Non-blocking I/O : 쓰레드의 실행을 중지시키지 않음 > 즉시 리턴
Asynchronous system call : 쓰레드의 코드를 계속해서 실행

File system : 파일 / 폴더, 파일 시스템 자체는 일반적으로 많은 레벨로 구성됨 - application > logical file system > file-organization module > basic file system > I/O control > device

Access Methods
	* sequentail access - 순서대로
	* direct access - 랜덤

Directory structure : single-level / two-level / tree-structured / acyclic-graph / general graph

Allocation Method : 저장공간의 효율적인 사용 / 파일에 빠르게 접근
	* Contiguous : 외부 단편화 발생 > compaction 필요
	* Linked : contiguous의 문제 해결, sequential-access에는 유용하지만 무조건 파일의 처음부터 시작해야함 > FAT(file allocation table)을 사용
	* Indexed : fat가 없는 경우의 linked의 문제 해결, index block에 모든 포인터를 저장 > 각각의 파일은 index block을 소유


***


<24강>

Security : 사용자가 physical resources를 사용할 수 있도록 인증을 해주는 것, 권한없는 접근 / 악의적인 침입이나 변경 / 실수로부터 컴퓨터 자원을 보호
Protection : 권한이 부여된 프로세스만이 memory segments / CPU 등의 자원에 접근할 수 있도록 하는 것

컴퓨터의 자원이 실수 혹은 고의로 잘못 사용될 수 있기 때문에 공격으로부터 막는 메커니즘이 필요함 > 암호화가 보안의 핵심 요소

Security Violations
* threat : security violation을 발생시킬 수 있는 가능성, 실수
* attack : 보안을 파괴하고자 하는 시도, 고의
비밀 / 완전성 / 유용성 위반, 서비스 도둑질, 서비스 부정(DoS) / 분산된 DoS(DDoS)

Levels of Security
Physical / Network / Operating System / Application

Security holes
* Malware : 컴퓨터 시스템을 해할 목적으로 디자인된 소프트웨어, 트로이목마 / spyware / 랜섬웨어 등
* Code Injection : 대부분의 소프트웨어는 악의적이지 않지만 code-injection 공격을 통해 심각한 위협을 가할 수 있음
* Virus : 합법적 프로그램에 포함된 코드의 단편, 자기복제와 감염
* Worm : 사용자의 행동 없이 네트워크를 통해 복제

Thereats in System and the Network
* sniffing : 공격자가 수동적인 상태로 네트워크 트래픽을 가로챔
* spoofing : 당사자로 가장하여 가로챔
* Denial of Service : 자원을 가로채거나 정보를 얻는 것을 목적으로 하지 않고 시스템을 방해하는 것이 목적
* Port Scanning : 포트 스캐닝 자체는 공격이 아닌 취약성을 찾아내는 용도

Cryptography : 네트워크 컴퓨터에서는 sender와 receiver가 네트워크상에서 메세지를 주고받을 가능성이 존재 - 운영체제가 어떻게 메세지를 신용할것인가 > 암호 작성을 통해 네트워크를 신용할 필요를 제거시켜줌, Encryption(암호화) / decyrption(복호화) 

암호화 알고리즘
* symmetric - 암호화와 복호화에 같은 키 사용 (사물함 공유), 키 교환은 서로 직접하거나 혹은 신뢰할 수 있는 third party(인증서)를 통해
	DES(Data Encryption Standard) / AES(Advanced Encryption Standard)
* asymmetric - 암호화와 복호화에 서로 다른 키 사용, public key와 private key 존재(ex 계좌번호 / 비밀번호)
	RAS(Rivest, Shamir, and Adleman) 알고리즘을 가장 많이 사용

Authentication : 암호화는 양방향 / 인증은 단방향 > hashing, 메시지가 수정되지 않았다는 것을 증명하는데도 유용
	* Digital Signature 알고리즘
	* MAC(Messsage-Authentication Code)

Protection : 프로세스와 유저의 권한이 부여된 접근을 제어, 공유 자원의 접근 및 인터넷과 같은 insecure communication platform과 연결시 신뢰성을 증가

최소 권한의 법칙 : 행동을 수행하는데 딱 필요한만큼의 권한을 부여
Access Matrix : 일반적인 모델, ACL(Access Control List, 행은 도메인 / 열은 오브젝트)를 만들어 권한을 체크

Sandboxing : 실행중인 프로세스가 자신이 할 수 있는 것만 하도록 한정, 프로세스는 유저의 인증서와 함께 실행되어 사용자가 엑세스할 수 있는 모든 항목에 엑세스할 수 있음
Code Sigining : 시스템이 프로그램을 어떻게 신뢰하는가 - 프로그램 및 실행파일이 생성된 후 변경되지 않았음을 확인하는 디지털 서명을 생성
